{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Este script tiene por objetivo realizar data augmentation de datos de resonancia magnetica estructural mediante la\n",
    "librer√≠a torchIO. TorchIO es una libreria versatil que permite realizar data augmentation en 3D para despues introducirlo\n",
    "facilmente en una red neuronal implementada en Pytorch. Ademas, permite preparar los datos sin leerlos desde el disco \n",
    "hasta el momento del entrenamiento para evitar problemas de memoria RAM. Ya que la pipeline implementada en este github\n",
    "utiliza una red neuronal en keras, las imagenes se leen, se augmentan y se lleva a cabo histogram matching,\n",
    "y despues se guardan los archvios generados.\n",
    "\n",
    "TorchIO esta preparada para tareas donde las etiquetas no son un solo numero, sino imagenes con unos para \n",
    "la region de interes y zeros para el resto. No esta directamente implementada las etiquetas binarias\n",
    "para la clasificacion entre pacientes y sujetos sanos utilizando toda la imagen. Por eso las imagenes de ambos\n",
    "grupos se leen separadamente para este script. Cabe destacar que el autor de este codigo no es un programador,\n",
    "por lo que sin duda el codigo puede ser simplificado por aquellos que sepan como hacerlo (por ejemplo, creando funciones\n",
    "heredadas). A pesar de no ser optimo, funciona.\n",
    "\n",
    "Documentacion de torchIO con ejemplos y tutoriales: https://torchio.readthedocs.io/\n",
    "Informacion sobre permitir etiquetas que no sean imagenes: https://github.com/fepegar/torchio/issues/112\n",
    "\n",
    "This script has the goal to perform data augmentation on structural magnetic resonance imaging using torchIO. \n",
    "TorchIO is a library which allows to permorm 3D data augmentation to further introduce easily the data in a \n",
    "neural net implemented in Pytorch. Furthermore, it allows to set up the data without reading them from the disk \n",
    "until the moment of training, avoiding memory issues. As the code in this github is implemented in keras this script\n",
    "is donde to read the file, perform data augmentation and histogram matching, and save them on disk.\n",
    "\n",
    "TorchIO is set up for tasks where the label is not a single number, but an image with ones for a region of interest\n",
    "and zeros for the rest. Groups are readed separately to add the label manually. It is worth mentioning that\n",
    "the author of this code is not a programmer so this code can be simplified and optimized. Even though it is\n",
    "not perfect, it does work.\n",
    "\n",
    "Documentation about torchIO with examples and tutorials: https://torchio.readthedocs.io/\n",
    "Info about allowing labels that are not images: https://github.com/fepegar/torchio/issues/112\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import time\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchio as tio\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from unet import UNet\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "#evitar un warning\n",
    "from scipy.ndimage import measurements\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set variables:\n",
    "\"\"\"\n",
    "histogram_landmarks_path = 'landmarks.npy'\n",
    "#crop = (15, 8, 15, 4, 1, 14) si se quiere recortar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneGroupPath = \"PATH\"\n",
    "AnotherGroupPath = \"AnotherPATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Crear clase subject para ambos grupos (para poder etiquetarlos) y despues crear un solo SubjectsDataset\n",
    "Create subject class for both groups (so you can label then) and then create only one SubjectDataset\n",
    "\"\"\"\n",
    "\n",
    "subjects = []\n",
    "\n",
    "# Usar zip si el formato de las imagenes es .nii.gz\n",
    "# Zip is used in case images are in .nii.gz format\n",
    "for OneGroupPath in zip(OneGroupPath):\n",
    "    subject = tio.Subject(\n",
    "    mri = tio.ScalarImage(OneGroupPath),\n",
    "    label = torch.tensor(1)\n",
    "    )\n",
    "    subjects.append(subject)\n",
    "    \n",
    "for AnotherGroupPath in zip(AnotherGroupPath):\n",
    "    subject = tio.Subject(\n",
    "    mri = tio.ScalarImage(AnotherGroupPath),\n",
    "    label = torch.tensor(0)\n",
    "    )\n",
    "    subjects.append(subject)\n",
    "    \n",
    "dataset = tio.SubjectsDataset(subjects)\n",
    "print(\"Dataset size: \", len(dataset), \" subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calcular landmarks para histogram standarization\n",
    "Calculate landmarks for histogram standarization\n",
    "\"\"\"\n",
    "\n",
    "landmarks = tio.HistogramStandardization.train(\n",
    "    whole_image_path,\n",
    "    output_path = histogram_landmarks_path,\n",
    ")\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "print('\\nTrained landmarks:', landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transformaciones antes de augmentar o validar\n",
    "Transformations done before augmentation or validation\n",
    "\"\"\"\n",
    "\n",
    "landmarks_dict = {\"mri\" : landmarks}\n",
    "pre_augmentation_transfrom = tio.Compose([\n",
    "    tio.HistogramStandardization({\"mri\":landmarks}),\n",
    "    #tio.Crop(crop), para cortar las imagenes / in case you want to crop images\n",
    "    #tio.Resample(1.8) para modificar la resolucion / in case you want to resize the images\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Crear train set y validation set para el data augmentation\n",
    "Create train set and validation set before data augmentation\n",
    "\"\"\"\n",
    "\n",
    "# Generar los sets de entrenamiento y validacion\n",
    "# Generate training and validation sets\n",
    "\n",
    "training_split_ratio = 0.8\n",
    "num_subjects = len(dataset)\n",
    "num_training_subjects = int(training_split_ratio * num_subjects)\n",
    "num_validation_subjects = num_subjects - num_training_subjects\n",
    "\n",
    "num_split_subjects = num_training_subjects, num_validation_subjects\n",
    "\n",
    "training_subjects, validation_subjects = torch.utils.data.random_split(\n",
    "    subjects, num_split_subjects, generator=torch.Generator().manual_seed(17))\n",
    "\n",
    "# Realizar las transformaciones previas al augmentation (histogram mactching, crop, resample)\n",
    "# Perform transforms before augmentation (histogram mactching, crop, resample)\n",
    "training_set = tio.SubjectsDataset(\n",
    "    training_subjects, transform=pre_augmentation_transfrom)\n",
    "\n",
    "validation_set = tio.SubjectsDataset(\n",
    "    validation_subjects, transform=pre_augmentation_transfrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Guardar sets para controlar que imagenes estan en que set\n",
    "Save sets to have control of which images are in which set\n",
    "\"\"\"\n",
    "\n",
    "contador = 1\n",
    "for subject in validation_set:\n",
    "    data, affine = subject.mri.data, subject.mri.affine\n",
    "    data = data.numpy()\n",
    "    data = data.squeeze(axis=0)\n",
    "    val_nii = nib.Nifti1Image(data, affine)\n",
    "    nib.save(val_nii, \"path_to_save_val_set/SubjectNumber\" +str(contador)+ \"/struct.nii.gz\")\n",
    "    torch.save(subject.label, \"path_to_save_val_Set/SubjectNumber\" +str(contador)+ \"/label\")\n",
    "    contador +=1\n",
    "    \n",
    "contador = 1\n",
    "for subject in training_set:\n",
    "    data, affine = subject.mri.data, subject.mri.affine\n",
    "    data = data.numpy()\n",
    "    data = data.squeeze(axis=0)\n",
    "    train_nii = nib.Nifti1Image(data, affine)\n",
    "    nib.save(val_nii, \"path_to_save_train_set/SubjectNumber\" +str(contador)+ \"/struct.nii.gz\")\n",
    "    torch.save(subject.label, \"path_to_save_train_Set/SubjectNumber\" +str(contador)+ \"/label\")\n",
    "    contador +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Para utilizar el codigo literalmente debes crear estas carpetas\n",
    "To use this code literally you have to create this folders\n",
    "\"data_augmentations/gamma/gammasubj1\"\n",
    "\"data_augmentations/gamma/gammasubj2\"\n",
    "...\n",
    "\"data_augmentations/noise/aug_noisesubj1\"\n",
    "\"data_augmentations/noise/aug_noisesubj2\"\n",
    "...\n",
    "y asi sucesivamente\n",
    "and so on\n",
    "\"\"\"\n",
    "\n",
    "gamma_subj_path = os.listdir(\"data_augmentations/gamma/\")\n",
    "noise_subj_path = os.listdir(\"data_augmentations/noise/\")\n",
    "rotation_subj_path = os.listdir(\"data_augmentations/rotation/\")\n",
    "scaling_subj_path = os.listdir(\"data_augmentations/scaling/\")\n",
    "shift_subj_path = os.listdir(\"data_augmentations/shift/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data augmentation para el training set y guardarlo en disco. El path para guardar las etiquetas y las imagenes depende\n",
    "de como se quiere que sea la estructura de carpetas. La usada aqui es solo una opcion.\n",
    "Data augmentation for training set and save it to disk. The paths were to save the augmented images and\n",
    "labels depends on how you want the folder structure. The one here is just an option.\n",
    "\"\"\"\n",
    "\n",
    "contador_subj = 1\n",
    "for subject in training_set:\n",
    "    #Gamma\n",
    "    torch.save(subject.label, \"data_augmentations/gamma/gammasubj\"+str(contador_subj)+ \"/label\")\n",
    "    gammas = tio.Gamma(gamma = None)\n",
    "    gamma_aug = []\n",
    "    value = 0.7\n",
    "    while value <= 1.3:\n",
    "        gammas.gamma = value\n",
    "        augmentation_gamma = gammas(subject.mri)\n",
    "        gamma_aug.append(augmentation_gamma)\n",
    "        value += 0.2\n",
    "        contador_img = 1\n",
    "    for augmentation in gamma_aug:\n",
    "        data, affine = augmentation.data, augmentation.affine\n",
    "        data = data.numpy()\n",
    "        data = data.squeeze(axis=0)\n",
    "        gamma_nii = nib.Nifti1Image(data, affine)\n",
    "        nib.save(gamma_nii,\n",
    "                    \"data_augmentations/gamma/gammasubj\"+str(contador_subj)+ \"/gamma\"+str(contador_img)+\".nii.gz\")\n",
    "        contador_img +=1\n",
    "\n",
    "    #Gaussian Noise\n",
    "    torch.save(subject.label, \"data_augmentations/noise/noisesubj\"+str(contador_subj)+ \"/label\")\n",
    "    noise = tio.Noise(mean=0, std=0.1, seed=None)\n",
    "    noise_aug = []\n",
    "    seed = 0\n",
    "    while seed <= 30:\n",
    "        noise.seed = seed\n",
    "        augmentetation_noise = noise(subject.mri)\n",
    "        noise_aug.append(augmentetation_noise) \n",
    "        seed += 10\n",
    "        contador_img = 1\n",
    "    for augmentation in noise_aug:\n",
    "        data, affine = augmentation.data, augmentation.affine\n",
    "        data = data.numpy()\n",
    "        data = data.squeeze(axis=0)\n",
    "        noise_nii = nib.Nifti1Image(data, affine)\n",
    "        nib.save(noise_nii,\n",
    "                    \"data_augmentations/noise/noisesubj\"+str(contador_subj)+ \"/noise\"+str(contador_img)+\".nii.gz\")\n",
    "        contador_img +=1\n",
    "        \n",
    "    #Image rotation:\n",
    "    torch.save(subject.label, \"data_augmentations/rotation/rotationsubj\"+str(contador_subj)+ \"/label\")\n",
    "    rotation_aug = []\n",
    "    angle = -16\n",
    "    while angle <= 16:\n",
    "        rotation = tio.Affine(scales=1, degrees=angle, translation=0)\n",
    "        augmentetation_rotation = rotation(subject.mri)\n",
    "        rotation_aug.append(augmentetation_rotation) \n",
    "        angle += 8\n",
    "        contador_img = 1\n",
    "    for augmentation in rotation_aug:\n",
    "        data, affine = augmentation.data, augmentation.affine\n",
    "        data = data.numpy()\n",
    "        data = data.squeeze(axis=0)\n",
    "        rotation_nii = nib.Nifti1Image(data, affine)\n",
    "        nib.save(rotation_nii,\n",
    "                    \"data_augmentations/rotation/rotationsubj\"+str(contador_subj)+ \"/rotation\"+str(contador_img)+\".nii.gz\")\n",
    "        contador_img +=1\n",
    "        \n",
    "    #Scaling\n",
    "    torch.save(subject.label, \"data_augmentations/scaling/scalingsubj\"+str(contador_subj)+ \"/label\")\n",
    "    scaling_aug = []\n",
    "    scaling_factor = 0.7\n",
    "    while scaling_factor <= 1.3:\n",
    "        scaling = tio.Affine(scales=scaling_factor, degrees=0, translation=(0,0,0))\n",
    "        augmentation_scaling = scaling(subject.mri)\n",
    "        scaling_aug.append(augmentation_scaling)\n",
    "        scaling_factor += 0.2\n",
    "        contador_img = 1\n",
    "    for augmentation in scaling_aug:\n",
    "        data, affine = augmentation.data, augmentation.affine\n",
    "        data = data.numpy()\n",
    "        data = data.squeeze(axis=0)\n",
    "        scaling_nii = nib.Nifti1Image(data, affine)\n",
    "        nib.save(scaling_nii,\n",
    "                    \"data_augmentations/scaling/scalingsubj\"+str(contador_subj)+ \"/scaling\"+str(contador_img)+\".nii.gz\")\n",
    "        contador_img +=1\n",
    "    \n",
    "    #shift\n",
    "    torch.save(subject.label, \"data_augmentations/shift/shiftsubj\"+str(contador_subj)+ \"/label\")\n",
    "    shift = tio.RandomAffine(scales=0, degrees=0, translation=(70))\n",
    "    shift_aug = []\n",
    "    numero = 0\n",
    "    while numero <= 30:\n",
    "        augmentation_shift = shift(subject.mri)\n",
    "        shift_aug.append(augmentation_shift)\n",
    "        numero +=10\n",
    "        contador_img = 1\n",
    "    for augmentation in shift_aug:\n",
    "        data, affine = augmentation.data, augmentation.affine\n",
    "        data = data.numpy()\n",
    "        data = data.squeeze(axis=0)\n",
    "        shift_nii = nib.Nifti1Image(data, affine)\n",
    "        nib.save(shift_nii,\n",
    "                    \"data_augmentations/shift/shiftsubj\"+str(contador_subj)+ \"/shift\"+str(contador_img)+\".nii.gz\")\n",
    "        contador_img +=1\n",
    "    \n",
    "    contador_subj += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject(Keys: ('mri', 'label'); images: 1)\n",
      "ScalarImage(shape: (1, 193, 229, 193); spacing: (1.00, 1.00, 1.00); orientation: RAS+; memory: 32.5 MiB; dtype: torch.FloatTensor)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comprobar informacion de un sujeto en el dataset\n",
    "Check the info for one subject of the dataset\n",
    "\"\"\"\n",
    "\n",
    "one_subject = dataset[78]\n",
    "print(one_subject)\n",
    "print(one_subject.mri)\n",
    "print(one_subject.label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
