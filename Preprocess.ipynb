{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "El preprocesado implementado en este codigo se realiza a traves de la libreria nipype. Nipype es un wrapper\n",
    "que permite utilizar las funciones de diferentes softwares de resonacia magnetica (FSL, ANTs, FreeSurfer, AFNI...)\n",
    "directamente en Python al mismo tiempo. Para poder utilizar las funciones ES NECESARIO TENER INSTALADOS DICHOS SOFTWARES EN TU ORDENADOR.\n",
    "Un gran tutorial sobre nipype y como instalar dichos softwares puede encontrarse en:\n",
    "https://miykael.github.io/nipype-beginner-s-guide/index.html\n",
    "https://miykael.github.io/nipype_tutorial/\n",
    "\n",
    "The preprocessing implemented in this code is mainly done with nipype library. Nipype is a wrapper which allows\n",
    "to use functions from different magnetic resonance imaging softwares (FSL, ANTS, FreeSurfer, AFNI...) directly in\n",
    "Python and at the same time. In order to use these functions IT IS MANDATORY TO HAVE THESE SOFTWARES INSTALLED IN YOUR COMPUTER.\n",
    "A great tutorial on nipype and how to install these software can be found in:\n",
    "https://miykael.github.io/nipype-beginner-s-guide/index.html\n",
    "https://miykael.github.io/nipype_tutorial/\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importar dependencias\n",
    "Import modules\n",
    "\"\"\"\n",
    "\n",
    "from nipype.interfaces.fsl import BET, FLIRT, ImageMaths, ImageStats\n",
    "import nipype.interfaces.spm as spm\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "import nibabel as nib\n",
    "from nibabel.processing import resample_to_output\n",
    "from nipype.interfaces.fsl import Reorient2Std\n",
    "import numpy as np\n",
    "from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "from nipype.interfaces.utility import Function\n",
    "from os.path import join as opj\n",
    "from nibabel.testing import data_path\n",
    "from nipype.interfaces.slicer.filtering import histogrammatching\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "import nipype.interfaces.io as nio\n",
    "import multiprocessing as MultiProc\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "\n",
    "\n",
    "# Sin estos paquetes aparece un warning al crear el workflow\n",
    "# without these packages a warning pops up while creating the workflow\n",
    "from scipy.ndimage import measurements\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Asocia el codigo con el path donde estas trabajando (experiment_dir), donde encontrar los datos (data_dir) y la\n",
    "lista de imagenes dentro del data_dir\n",
    "Link the code to the path where you are working (experiment_dir), where to find the data (data_dir) and the list of\n",
    "images inside the data_dir\n",
    "\"\"\"\n",
    "\n",
    "experiment_dir = \"PATH\"\n",
    "data_dir = opj(\"PATH/data\") #Mas sencillo si los datos se encuentran dentro del experiment_dir / It's easier if data_dir is inside experimet_dir\n",
    "\n",
    "image_list = [\"imagen001\", \"imagen002\", \"imagen003\", \"imagen004\",\n",
    "              \"imagen005\", \"imagen006\", \"imagen007\", \"imagen008\",\n",
    "              \"imagen009\", \"imagen010\"]\n",
    "#Nombres de las carpetas que contienen los archivos .nii / Names of the folder which contains the .nii files\n",
    "#Los nombres de las imagenes deben tener los mismos nombres (imagen001/struct.nii, imagen002/struct.nii,...)\n",
    "#The names of the images must have the same names (image001/struct.nii, image002/struct.nii,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Especificar las variables de las funciones que se van a utilizar y el nombre de la estructura de carpetas del output\n",
    "Specify the arguments of the functions to use and the names of the folder structure of the output\n",
    "\"\"\"\n",
    "\n",
    "#Para la extraccion del cerebro con BET de FSL\n",
    "# For brain extraction with FSL's BET \n",
    "frac = 0.1\n",
    "reduce_bias = True\n",
    "\n",
    "#Registro lineal con FLIRT de FSL\n",
    "#Linear Registration with FSL's FLIRT\n",
    "\n",
    "template = \"path_to_template\" #Por ejemplo MNI152 / for example MNI152\n",
    "\n",
    "#Files\n",
    "output_dir = \"folder_name_for_final_image\" #Carpeta para la ultima imagen\n",
    "working_dir = \"folder_name_for_intermediate_images\" #Carpeta para las imagenes intermedias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Especificar los nodos que contienen las funciones del preprocesado\n",
    "Specify the nodes which contains the preprocessing functions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Extraer archivos comprimidos .nii.gz a .nii pues N4 necesita archivos descomprimidos como input\n",
    "# Extract compressed files .nii.gz to .nii because N4 require uncompressed files as input\n",
    "gunzip = Node(Gunzip(), name=\"gunzip\")\n",
    "\n",
    "#Correccion de la inhomogeneidad con N4 de ANTs\n",
    "#Bias correction with ANTs' N4\n",
    "n4 = Node(N4BiasFieldCorrection(), name = \"bias_correction\")\n",
    "\n",
    "#Extraccion del cerebro con BET\n",
    "#Brain extraction\n",
    "bet = Node(BET(), name = \"bet\")\n",
    "bet.inputs.frac = frac\n",
    "bet.inputs.reduce_bias = reduce_bias\n",
    "\n",
    "#Reorientar para el registro\n",
    "#Reorient before registration\n",
    "reorient = Node(Reorient2Std(), name = \"reorient\")\n",
    "\n",
    "#Registro lineal con FLIRT\n",
    "#Linear registration FLIRT\n",
    "flirt = Node(FLIRT(), name = \"flirt\")\n",
    "\n",
    "flirt.inputs.reference = template\n",
    "\n",
    "#Normalizacion de la intensidad mediante min-max, la opción op_string='-r' elimina los valores extremos de la normalizacion, -R los mantiene\n",
    "#Intensity min max normalization, argument op_string='-r' remove extreme values from the normalization, -R keeps them.\n",
    "\n",
    "fslstats = MapNode(interface = ImageStats(op_string='-r'),\n",
    "                          name = 'fslstats', iterfield=['in_file'])\n",
    "def min_max(in_stat):\n",
    "    min_val, max_val = in_stat\n",
    "    return '-sub %s -div %s' % (min_val, (max_val-min_val))\n",
    "\n",
    "stat_to_op_string = MapNode(interface=Function(input_names=['in_stat'],\n",
    "                                                output_names=['op_string'],\n",
    "                                                function=min_max),\n",
    "                                   name='stat_to_op_string', iterfield=['in_stat'])\n",
    "\n",
    "fslmaths = MapNode(interface = ImageMaths(),\n",
    "                          name = 'fslmaths', iterfield=['in_file', 'op_string'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Especificar los nodos de input y output\n",
    "Specify input and output nodes\n",
    "\"\"\"\n",
    "\n",
    "#Recoge las imagenes como input con el nombre de variable \"image_id\"\n",
    "#Picks the images as inputs with the variable name \"image_id\"\n",
    "infosource = Node(IdentityInterface(fields = [\"image_id\"]), \n",
    "                    name = \"infosource\")\n",
    "\n",
    "#Transforma las carpetas que contienen las images recogidas en image_list en iterables \"image_id\"\n",
    "#Transforms the folder that contains the images in image_list into iterables \"image_id\" \n",
    "infosource.iterables = [('image_id', image_list)]\n",
    "\n",
    "#En caso de que se utilicen más de un tipo de imagen (T1, T2, funcional...), recoge cada tipo en un diccionario, en este caso concreto solo hay una estructural, bajo la key:anat\n",
    "#In case that more than one type of image are used (T1, T2, functional...), it picks each kind in a dictionary, in this particular case only one kind is used under the key:anat\n",
    "templates = {'anat': 'data_dir/{image_id}/name_of_the_images.nii.gz'}\n",
    "selectfiles = Node(nio.SelectFiles(templates,\n",
    "                                  base_directory = experiment_dir), name=\"selectfiles\")\n",
    "\n",
    "\n",
    "datasink = Node(nio.DataSink(), name=\"datasink\")\n",
    "datasink.inputs.base_directory = \"PATH_to_folder\" (working_dir) # nombre de la carpeta donde guardar las imagenes intermedias / name of the folder where to save the intermediate images\n",
    "datasink.inputs.container = \"PATH_to_folder\" (output_dir) # nombre de la carpeta donde guardar la imagen final / name of the folder where to save the final image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Crear workflow y determinar su directorio\n",
    "Create the workflow and determinate its directories\n",
    "\"\"\"\n",
    "\n",
    "preprocess_workflow = Workflow(name = \"preprocess_full_workflow\")\n",
    "preprocess_workflow.base_dir = opj(experiment_dir, working_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conectar los nodos\n",
    "Conect the nodes\n",
    "\"\"\"\n",
    "\n",
    "#Escribe el input y outpu de cada nodo. Cada funcion utiliza diferentes nombres para los inputs y outputs\n",
    "#Write the input and output for each node. Each function has its own name for inputs and outputs\n",
    "\n",
    "preprocess_workflow.connect([\n",
    "                    (infosource, selectfiles, [(\"image_id\", \"image_id\")]),\n",
    "                    (selectfiles, gunzip, [(\"anat\", \"in_file\")]),\n",
    "                    (gunzip, n4, [(\"out_file\", \"input_image\")]),\n",
    "                    (n4, reorient, [(\"output_image\", \"in_file\")]),\n",
    "                    (reorient, bet, [(\"out_file\", \"in_file\")]),\n",
    "                    (bet, flirt, [(\"out_file\", \"in_file\")]),\n",
    "                    (flirt, fslstats, [(\"out_file\", \"in_file\")]),\n",
    "                    (flirt, fslmaths, [(\"out_file\", \"in_file\")]),\n",
    "                    (fslstats, stat_to_op_string, [('out_stat', 'in_stat')]),\n",
    "                    (stat_to_op_string, fslmaths, [('op_string', 'op_string')]),\n",
    "                    (fslmaths, datasink, [(\"out_file\", \"resultados\")]),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ejecuta el workflow\n",
    "Execute the workflow\n",
    "\"\"\"\n",
    "#Puede hacerse en serie o en paralelo. En este caso es en paralelo utiliza 6 nucleos del procesador\n",
    "#This can be donde either secuencially or in parallel. In this case is done in parallel with 6 cores of the CPU.\n",
    "\n",
    "preprocess_workflow.run('MultiProc', plugin_args={'n_procs': 6})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
