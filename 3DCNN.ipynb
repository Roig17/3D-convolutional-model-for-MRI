{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Este código implementa una red neuronal convolucional en tres dimensiones (3DCNN) en keras para clasificacion\n",
    "binaria. Un tutorial con una red similar puede encontrarse en  https://keras.io/examples/vision/3D_image_classification/\n",
    "This code implements a 3D convolutional neural network in keras (3DCNN) for binary classification.\n",
    "A similar network tutorial can be found in https://keras.io/examples/vision/3D_image_classification/\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importar dependencias\n",
    "Import dependencies\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.keras.layers import Conv3D, BatchNormalization, MaxPool3D, GlobalAveragePooling3D, Dense, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import schedules, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comprobar la lista de GPUs activadas para el entrenamiento\n",
    "Check number of GPUs activated for training\n",
    "\"\"\"\n",
    "len(tf.config.experimental.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Para agilizar la carga de las imagenes estas fueron convertidas previamente en arrays de numpy\n",
    "(tamaño del set x alto x ancho x largo)\n",
    "To make loading the images easier, these where previosly converted into numpy arrays of size \n",
    "(size of the set x hight x width x depth)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cargar los sets de entrenamiento, validacion y test\n",
    "Load training, validation and test sets\n",
    "\"\"\"\n",
    "\n",
    "x_train = np.load(\"x_train_aug.npy\")\n",
    "y_train = np.load(\"y_train_aug.npy\")\n",
    "\n",
    "x_val = np.load(\"x_val_aug.npy\")\n",
    "y_val = np.load(\"y_val_aug.npy\")\n",
    "\n",
    "x_test = np.load(\"x_test_aug.npy\")\n",
    "y_test = np.load(\"y_test_aug.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Añadir un canal: las convoluciones 3D en keras necesitan un input \n",
    "de 5 dimensiones; [batch_size, alto, ancho, profundidad, 1]. Ahora \n",
    "se añade esa quinta dimension que es 1 canal\n",
    "Add a channel: 3D convolutions in keras require an input of 5 dimensions;\n",
    "[batch_size, hight, widht, depth, 1]. This funtion add the five dimension\n",
    "which is 1 channel\n",
    "\"\"\"\n",
    "\n",
    "def training_channel(image, label):\n",
    "    image = tf.expand_dims(image, axis = 3)\n",
    "    return image, label\n",
    "\n",
    "def test_channel(image, label):\n",
    "    image = tf.expand_dims(image, axis = 3)\n",
    "    return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definir los loaders\n",
    "Define loaders\n",
    "\"\"\"\n",
    "# definir los loaders\n",
    "\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "val_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "batch_size = 8\n",
    "val_batch_size = 12\n",
    "\n",
    "# añadir el canal durante el training\n",
    "# add channel on the fly of training\n",
    "\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(training_channel)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2))\n",
    "\n",
    "# para el validation, añadir el canal\n",
    "# the same for the validation set\n",
    "\n",
    "val_dataset = (\n",
    "    val_loader.shuffle(len(x_val))\n",
    "    .map(test_channel)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definir el modelo\n",
    "Define the model\n",
    "\"\"\"\n",
    "\n",
    "def get_model(width = 95, height = 117, depth = 99):\n",
    "    \n",
    "    \n",
    "    inputs = Input((width, height, depth, 1))\n",
    "    \n",
    "    x = Conv3D(8, (5,5,5), padding = \"same\", strides = 1, activation = \"relu\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv3D(16, (3,3,3), padding = \"same\", strides = 1, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D(pool_size = (3,3,3), strides = (2,2,2))(x)\n",
    "\n",
    "    x = Conv3D(16, (3,3,3), padding = \"same\", strides = 1, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv3D(32, (3,3,3), padding = \"same\", strides = 1, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((3,3,3), strides = (2,2,2))(x)\n",
    "\n",
    "    x = Conv3D(32, (3,3,3), padding = \"same\",strides = 1, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv3D(64, (3,3,3), padding = \"same\", strides = 1, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((3,3,3), strides = (2,2,2))(x)\n",
    "\n",
    "    x = Conv3D(64, (3,3,3), padding = \"same\",strides = 1, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv3D(128, (3,3,3), padding = \"same\", strides = 1, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = MaxPool3D((3,3,3), strides = (2,2,2))(x)\n",
    "    \n",
    "    #x = Conv3D(128, (3,3,3), padding = \"same\",strides = 1, activation = \"relu\")(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "\n",
    "    #x = Conv3D(256, (3,3,3), padding = \"same\", strides = 1, activation = \"relu\")(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling3D()(x)\n",
    "    \n",
    "    x = Dense(128, activation = \"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = Dense(1, activation = None)(x)\n",
    "    \n",
    "    model = Model(inputs, outputs, name = \"3Dcnn\")\n",
    "    return model\n",
    "\n",
    "# Algunas capas estan comentadas porque el modelo definitivo fue menor de lo esperado\n",
    "# Some layers are commented becasuse the ultimate model was smaller than expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3Dcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 95, 117, 99, 1)]  0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 95, 117, 99, 8)    1008      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 95, 117, 99, 8)    32        \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 95, 117, 99, 16)   3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 95, 117, 99, 16)   64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 47, 58, 49, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 47, 58, 49, 16)    6928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 47, 58, 49, 16)    64        \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 47, 58, 49, 32)    13856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 47, 58, 49, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 23, 28, 24, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 23, 28, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 23, 28, 24, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 23, 28, 24, 64)    55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 23, 28, 24, 64)    256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 11, 13, 11, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 11, 13, 11, 64)    110656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 11, 13, 11, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 11, 13, 11, 128)   221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 11, 13, 11, 128)   512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 466,545\n",
      "Trainable params: 465,825\n",
      "Non-trainable params: 720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Obtener objeto modelo y su resumen\n",
    "Obtain model object and its summary\n",
    "\"\"\"\n",
    "\n",
    "model = get_model(width = 95, height = 117, depth = 99)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 239 steps, validate for 2 steps\n",
      "Epoch 1/75\n",
      "239/239 - 206s - loss: 0.7490 - binary_accuracy: 0.5118 - val_loss: 0.6944 - val_binary_accuracy: 0.4615\n",
      "Epoch 2/75\n",
      "239/239 - 189s - loss: 0.6990 - binary_accuracy: 0.5625 - val_loss: 0.9372 - val_binary_accuracy: 0.4615\n",
      "Epoch 3/75\n",
      "239/239 - 190s - loss: 0.6082 - binary_accuracy: 0.6531 - val_loss: 1.4788 - val_binary_accuracy: 0.5385\n",
      "Epoch 4/75\n",
      "239/239 - 192s - loss: 0.4835 - binary_accuracy: 0.7614 - val_loss: 0.3611 - val_binary_accuracy: 0.6923\n",
      "Epoch 5/75\n",
      "239/239 - 187s - loss: 0.4176 - binary_accuracy: 0.8032 - val_loss: 0.8209 - val_binary_accuracy: 0.5385\n",
      "Epoch 6/75\n",
      "239/239 - 186s - loss: 0.3306 - binary_accuracy: 0.8545 - val_loss: 0.5452 - val_binary_accuracy: 0.6154\n",
      "Epoch 7/75\n",
      "239/239 - 185s - loss: 0.2734 - binary_accuracy: 0.8838 - val_loss: 2.6316 - val_binary_accuracy: 0.6154\n",
      "Epoch 8/75\n",
      "239/239 - 185s - loss: 0.2189 - binary_accuracy: 0.9074 - val_loss: 3.4769 - val_binary_accuracy: 0.5385\n",
      "Epoch 9/75\n",
      "239/239 - 187s - loss: 0.1703 - binary_accuracy: 0.9320 - val_loss: 0.2314 - val_binary_accuracy: 0.9231\n",
      "Epoch 10/75\n",
      "239/239 - 184s - loss: 0.1688 - binary_accuracy: 0.9362 - val_loss: 0.1061 - val_binary_accuracy: 0.9231\n",
      "Epoch 11/75\n",
      "239/239 - 186s - loss: 0.1327 - binary_accuracy: 0.9498 - val_loss: 4.2621 - val_binary_accuracy: 0.6154\n",
      "Epoch 12/75\n",
      "239/239 - 186s - loss: 0.1401 - binary_accuracy: 0.9419 - val_loss: 2.9689 - val_binary_accuracy: 0.5385\n",
      "Epoch 13/75\n",
      "239/239 - 184s - loss: 0.1430 - binary_accuracy: 0.9430 - val_loss: 0.1394 - val_binary_accuracy: 1.0000\n",
      "Epoch 14/75\n",
      "239/239 - 185s - loss: 0.1172 - binary_accuracy: 0.9560 - val_loss: 0.0108 - val_binary_accuracy: 1.0000\n",
      "Epoch 15/75\n",
      "239/239 - 185s - loss: 0.0860 - binary_accuracy: 0.9707 - val_loss: 0.0241 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/75\n",
      "239/239 - 184s - loss: 0.0855 - binary_accuracy: 0.9655 - val_loss: 0.4143 - val_binary_accuracy: 0.7692\n",
      "Epoch 17/75\n",
      "239/239 - 186s - loss: 0.1027 - binary_accuracy: 0.9608 - val_loss: 0.2543 - val_binary_accuracy: 0.8462\n",
      "Epoch 18/75\n",
      "239/239 - 184s - loss: 0.0727 - binary_accuracy: 0.9785 - val_loss: 0.5353 - val_binary_accuracy: 0.8462\n",
      "Epoch 19/75\n",
      "239/239 - 186s - loss: 0.0915 - binary_accuracy: 0.9660 - val_loss: 0.1378 - val_binary_accuracy: 0.8462\n",
      "Epoch 20/75\n",
      "239/239 - 186s - loss: 0.0856 - binary_accuracy: 0.9660 - val_loss: 0.1770 - val_binary_accuracy: 0.8462\n",
      "Epoch 21/75\n",
      "239/239 - 185s - loss: 0.0681 - binary_accuracy: 0.9744 - val_loss: 6.3798 - val_binary_accuracy: 0.4615\n",
      "Epoch 22/75\n",
      "239/239 - 187s - loss: 0.1068 - binary_accuracy: 0.9608 - val_loss: 1.1835 - val_binary_accuracy: 0.5385\n",
      "Epoch 23/75\n",
      "239/239 - 184s - loss: 0.0961 - binary_accuracy: 0.9655 - val_loss: 0.2606 - val_binary_accuracy: 0.8462\n",
      "Epoch 24/75\n",
      "239/239 - 186s - loss: 0.0731 - binary_accuracy: 0.9723 - val_loss: 0.2437 - val_binary_accuracy: 0.9231\n",
      "Epoch 25/75\n",
      "239/239 - 187s - loss: 0.0686 - binary_accuracy: 0.9775 - val_loss: 1.3933 - val_binary_accuracy: 0.7692\n",
      "Epoch 26/75\n",
      "239/239 - 184s - loss: 0.0619 - binary_accuracy: 0.9754 - val_loss: 0.5972 - val_binary_accuracy: 0.7692\n",
      "Epoch 27/75\n",
      "239/239 - 187s - loss: 0.0515 - binary_accuracy: 0.9827 - val_loss: 1.0806 - val_binary_accuracy: 0.7692\n",
      "Epoch 28/75\n",
      "239/239 - 185s - loss: 0.0399 - binary_accuracy: 0.9848 - val_loss: 1.5242 - val_binary_accuracy: 0.5385\n",
      "Epoch 29/75\n",
      "239/239 - 185s - loss: 0.0605 - binary_accuracy: 0.9796 - val_loss: 3.6564 - val_binary_accuracy: 0.5385\n",
      "Epoch 30/75\n",
      "239/239 - 187s - loss: 0.0524 - binary_accuracy: 0.9780 - val_loss: 1.7753 - val_binary_accuracy: 0.6923\n",
      "Epoch 31/75\n",
      "239/239 - 184s - loss: 0.0527 - binary_accuracy: 0.9812 - val_loss: 0.5794 - val_binary_accuracy: 0.7692\n",
      "Epoch 32/75\n",
      "239/239 - 186s - loss: 0.0482 - binary_accuracy: 0.9838 - val_loss: 0.0727 - val_binary_accuracy: 0.9231\n",
      "Epoch 33/75\n",
      "239/239 - 185s - loss: 0.0883 - binary_accuracy: 0.9696 - val_loss: 9.1783 - val_binary_accuracy: 0.5385\n",
      "Epoch 34/75\n",
      "239/239 - 184s - loss: 0.0532 - binary_accuracy: 0.9765 - val_loss: 0.4714 - val_binary_accuracy: 0.7692\n",
      "Epoch 35/75\n",
      "239/239 - 186s - loss: 0.0538 - binary_accuracy: 0.9785 - val_loss: 0.1413 - val_binary_accuracy: 0.9231\n",
      "Epoch 36/75\n",
      "239/239 - 184s - loss: 0.0417 - binary_accuracy: 0.9833 - val_loss: 0.0203 - val_binary_accuracy: 1.0000\n",
      "Epoch 37/75\n",
      "239/239 - 185s - loss: 0.0596 - binary_accuracy: 0.9812 - val_loss: 0.0921 - val_binary_accuracy: 0.9231\n",
      "Epoch 38/75\n",
      "239/239 - 187s - loss: 0.0315 - binary_accuracy: 0.9864 - val_loss: 0.0573 - val_binary_accuracy: 0.9231\n",
      "Epoch 39/75\n",
      "239/239 - 183s - loss: 0.0499 - binary_accuracy: 0.9796 - val_loss: 0.3696 - val_binary_accuracy: 0.8462\n",
      "Epoch 40/75\n",
      "239/239 - 185s - loss: 0.0335 - binary_accuracy: 0.9890 - val_loss: 0.1019 - val_binary_accuracy: 0.9231\n",
      "Epoch 41/75\n",
      "239/239 - 186s - loss: 0.0359 - binary_accuracy: 0.9853 - val_loss: 0.2390 - val_binary_accuracy: 0.8462\n",
      "Epoch 42/75\n",
      "239/239 - 184s - loss: 0.0799 - binary_accuracy: 0.9712 - val_loss: 0.6224 - val_binary_accuracy: 0.6923\n",
      "Epoch 43/75\n",
      "239/239 - 187s - loss: 0.0355 - binary_accuracy: 0.9916 - val_loss: 0.0135 - val_binary_accuracy: 1.0000\n",
      "Epoch 44/75\n",
      "239/239 - 184s - loss: 0.0465 - binary_accuracy: 0.9822 - val_loss: 0.9116 - val_binary_accuracy: 0.7692\n",
      "Epoch 45/75\n",
      "239/239 - 185s - loss: 0.0523 - binary_accuracy: 0.9827 - val_loss: 0.1694 - val_binary_accuracy: 0.8462\n",
      "Epoch 46/75\n",
      "239/239 - 187s - loss: 0.0270 - binary_accuracy: 0.9911 - val_loss: 0.0475 - val_binary_accuracy: 0.9231\n",
      "Epoch 47/75\n",
      "239/239 - 184s - loss: 0.0579 - binary_accuracy: 0.9817 - val_loss: 0.5397 - val_binary_accuracy: 0.8462\n",
      "Epoch 48/75\n",
      "239/239 - 187s - loss: 0.0588 - binary_accuracy: 0.9780 - val_loss: 0.4813 - val_binary_accuracy: 0.8462\n",
      "Epoch 49/75\n",
      "239/239 - 186s - loss: 0.0363 - binary_accuracy: 0.9833 - val_loss: 0.0676 - val_binary_accuracy: 1.0000\n",
      "Epoch 50/75\n",
      "239/239 - 185s - loss: 0.0508 - binary_accuracy: 0.9822 - val_loss: 0.0544 - val_binary_accuracy: 1.0000\n",
      "Epoch 51/75\n",
      "239/239 - 186s - loss: 0.0384 - binary_accuracy: 0.9864 - val_loss: 0.0603 - val_binary_accuracy: 1.0000\n",
      "Epoch 52/75\n",
      "239/239 - 185s - loss: 0.0269 - binary_accuracy: 0.9895 - val_loss: 0.1352 - val_binary_accuracy: 0.9231\n",
      "Epoch 53/75\n",
      "239/239 - 187s - loss: 0.0501 - binary_accuracy: 0.9791 - val_loss: 0.0146 - val_binary_accuracy: 1.0000\n",
      "Epoch 54/75\n",
      "239/239 - 187s - loss: 0.0424 - binary_accuracy: 0.9848 - val_loss: 0.3898 - val_binary_accuracy: 0.9231\n",
      "Epoch 55/75\n",
      "239/239 - 185s - loss: 0.0303 - binary_accuracy: 0.9874 - val_loss: 0.4741 - val_binary_accuracy: 0.7692\n",
      "Epoch 56/75\n",
      "239/239 - 187s - loss: 0.0518 - binary_accuracy: 0.9822 - val_loss: 0.0505 - val_binary_accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "239/239 - 185s - loss: 0.0411 - binary_accuracy: 0.9853 - val_loss: 0.2688 - val_binary_accuracy: 0.9231\n",
      "Epoch 58/75\n",
      "239/239 - 185s - loss: 0.0379 - binary_accuracy: 0.9874 - val_loss: 0.2542 - val_binary_accuracy: 0.9231\n",
      "Epoch 59/75\n",
      "239/239 - 187s - loss: 0.0227 - binary_accuracy: 0.9922 - val_loss: 0.0286 - val_binary_accuracy: 1.0000\n",
      "Epoch 60/75\n",
      "239/239 - 184s - loss: 0.0322 - binary_accuracy: 0.9859 - val_loss: 0.0130 - val_binary_accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "239/239 - 187s - loss: 0.0458 - binary_accuracy: 0.9812 - val_loss: 0.1042 - val_binary_accuracy: 0.9231\n",
      "Epoch 62/75\n",
      "239/239 - 185s - loss: 0.0354 - binary_accuracy: 0.9890 - val_loss: 0.4403 - val_binary_accuracy: 0.8462\n",
      "Epoch 63/75\n",
      "239/239 - 184s - loss: 0.0205 - binary_accuracy: 0.9932 - val_loss: 0.0564 - val_binary_accuracy: 0.9231\n",
      "Epoch 64/75\n",
      "239/239 - 187s - loss: 0.0484 - binary_accuracy: 0.9833 - val_loss: 0.0442 - val_binary_accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "239/239 - 184s - loss: 0.0193 - binary_accuracy: 0.9937 - val_loss: 0.0029 - val_binary_accuracy: 1.0000\n",
      "Epoch 66/75\n",
      "239/239 - 185s - loss: 0.0091 - binary_accuracy: 0.9979 - val_loss: 0.9003 - val_binary_accuracy: 0.7692\n",
      "Epoch 67/75\n",
      "239/239 - 186s - loss: 0.0311 - binary_accuracy: 0.9880 - val_loss: 0.2431 - val_binary_accuracy: 0.9231\n",
      "Epoch 68/75\n",
      "239/239 - 183s - loss: 0.0356 - binary_accuracy: 0.9880 - val_loss: 0.8845 - val_binary_accuracy: 0.7692\n",
      "Epoch 69/75\n",
      "239/239 - 187s - loss: 0.0517 - binary_accuracy: 0.9812 - val_loss: 0.0280 - val_binary_accuracy: 1.0000\n",
      "Epoch 70/75\n",
      "239/239 - 184s - loss: 0.0389 - binary_accuracy: 0.9874 - val_loss: 0.0548 - val_binary_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/75\n",
      "239/239 - 184s - loss: 0.0096 - binary_accuracy: 0.9969 - val_loss: 0.0072 - val_binary_accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "239/239 - 186s - loss: 0.0185 - binary_accuracy: 0.9942 - val_loss: 0.2357 - val_binary_accuracy: 0.9231\n",
      "Epoch 73/75\n",
      "239/239 - 184s - loss: 0.0382 - binary_accuracy: 0.9838 - val_loss: 0.1928 - val_binary_accuracy: 0.9231\n",
      "Epoch 74/75\n",
      "239/239 - 186s - loss: 0.0379 - binary_accuracy: 0.9859 - val_loss: 0.1814 - val_binary_accuracy: 0.8462\n",
      "Epoch 75/75\n",
      "239/239 - 186s - loss: 0.0438 - binary_accuracy: 0.9833 - val_loss: 0.3869 - val_binary_accuracy: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3d86b0cc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Entrenar el modelo\n",
    "Train the model\n",
    "\"\"\"\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch = 8\n",
    "conv_layers = 8\n",
    "NAME = \"3DCNN{}-lr-{}-conv-{}-batch-{}\".format(learning_rate, conv_layers, batch, int(time.time()))\n",
    "\n",
    "# NAME da nombre al archivo que guardara el modelo para la posterior monitorizacion en tensorboard\n",
    "# NAME gives a name to the file in which the model will be save to be monitorized with tensorboard\n",
    "tb = TensorBoard(log_dir = \"logs/{}\".format(NAME))\n",
    "\n",
    "# Checkpoint guarda el mejor modelo segun la metrica elegida (monitor)\n",
    "# Checkpoint saves the model accordingly to the desired metric (monitor)\n",
    "checkpoint = ModelCheckpoint(\"best_model\", monitor = \"loss\",  verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "# Compile escoge una funcion de coste (BinaryCrossentropy) , el optimizador (Adam) y la metrica (BinaryAccuracy)\n",
    "# Compile chooses a cost fuction (BinaryCrossentropy), the optimizer (Adam) and the metric (BinaryAccuracy)\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = Adam(learning_rate = learning_rate),\n",
    "    metrics = [tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "\n",
    "# Entrenar el modelo\n",
    "# Train the model\n",
    "\n",
    "epochs = 75\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    epochs = epochs,\n",
    "    shuffle = True,\n",
    "    verbose = 2,\n",
    "    callbacks = [tb, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Guardar el modelo\n",
    "Save the model\n",
    "\"\"\"\n",
    "\n",
    "model.save(\"ModelName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test set\n",
    "\"\"\"\n",
    "\n",
    "# Añadir la dimension correspondiente al canal para el test set\n",
    "# Add channel dimension for the test set\n",
    "x_test_channel = np.expand_dims(x_test, axis=4)\n",
    "\n",
    "# Prediccion sobre el test set\n",
    "# Prediction over the test set\n",
    "preds = model.predict(x_test_channel)\n",
    "\n",
    "\n",
    "# El modelo esta implementado para dar como ouput el resultado sin activacion sigmoide, eso lo hace metrics.BinaryAccuracy, más informacion (en inglés) en:\n",
    "# https://medium.com/deep-learning-with-keras/which-activation-loss-functions-part-a-e16f5ad6d82a\n",
    "# This model is set to give the output without sigmoid activation, that is done by metrics.BinaryAccuracy, more info in:\n",
    "# https://medium.com/deep-learning-with-keras/which-activation-loss-functions-part-a-e16f5ad6d82a\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obtener las predicciones en unos y ceros\n",
    "# To obtain predictions in ones and zeros\n",
    "\n",
    "BinaryPreds = expit(preds)\n",
    "print(BinaryPreds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
